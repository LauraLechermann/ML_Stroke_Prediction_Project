{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d946f246-07f7-4f05-b60a-e02071722a8e",
   "metadata": {},
   "source": [
    "# **üì¶ Stroke Prediction Model ‚Äì Deployment Notebook**\n",
    "\n",
    "### **üß† Purpose:**\n",
    "This notebook loads the trained Logistic Regression model and preprocessing pipeline from the project and defines a prediction function. This is the minimal setup for:\n",
    "\n",
    "- Running **batch predictions**\n",
    "- Serving predictions via **web app (Streamlit)**\n",
    "- Ensuring that the pipeline and model behave as expected when exposed to new inputs\n",
    "\n",
    "### **üéØ Goals:**\n",
    "1. Load the saved model and preprocessing pipeline\n",
    "2. Create functions to handle new patient data\n",
    "3. Build a user-friendly web interface with Streamlit\n",
    "\n",
    "### **üìä Deployment Flow:**\n",
    "Raw Patient Data ‚Üí Feature Engineering ‚Üí Preprocessing ‚Üí Model ‚Üí Risk Prediction\n",
    "\n",
    "### **üîÅ What This Notebook Includes**\n",
    "- Load saved model, pipeline, and feature list\n",
    "- Define feature engineering class to recreate engineered features\n",
    "- Define `predict_stroke_risk()` to generate predictions from raw patient input\n",
    "- Run example predictions\n",
    "- Instructions for Streamlit deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f867081-5e89-492f-9672-5c869d2ed052",
   "metadata": {},
   "source": [
    "## **1Ô∏è‚É£ Setup: Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a70978a-fc53-40c8-bff0-390b11f8d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c31a90-9d72-4550-9985-70fd64432732",
   "metadata": {},
   "source": [
    "## **2Ô∏è‚É£ Load Model Artifacts and Saved Model Components**\n",
    "\n",
    "This section loads the trained model, preprocessing pipeline, and list of final feature names. These artifacts were saved from the development notebook and are required to ensure consistent inference during deployment.\n",
    "\n",
    "We saved three critical files during training:\n",
    "1. **final_model.pkl**: The trained Logistic Regression model\n",
    "2. **preprocessing_pipeline.pkl**: Handles scaling and encoding\n",
    "3. **feature_names.json**: List of features the model expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1095a1b8-d5f6-4ade-9d7e-1de1380e2c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FeatureSelector class defined\n"
     ]
    }
   ],
   "source": [
    "# Define FeatureSelector class (needed for loading the pipeline)\n",
    "class FeatureSelector:\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices]\n",
    "\n",
    "print(\"‚úÖ FeatureSelector class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f911bb-e4c2-4883-88ef-f0f806188bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Corrected artifacts loaded\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"final_model_artifacts/final_model.pkl\")\n",
    "pipeline = joblib.load(\"final_model_artifacts/preprocessing_pipeline.pkl\")\n",
    "with open(\"final_model_artifacts/feature_names.json\") as f:\n",
    "    feature_names = json.load(f) \n",
    "print(\"‚úÖ Corrected artifacts loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125eda0-b511-4856-8ffd-5999d095ff39",
   "metadata": {},
   "source": [
    "### **Info:**\n",
    "\n",
    "* `preprocessor` ‚Üí `pipeline` (name change to reflect it's now a 2-stage pipeline)\n",
    "* The files themselves contain different content (7-feature pipeline vs 30-feature preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d7bc1-e54a-4dfb-a6eb-6ec591857358",
   "metadata": {},
   "source": [
    "## **3Ô∏è‚É£ Feature Engineering for New Patients**\n",
    "\n",
    "### ‚ùì Why do we need this?\n",
    "During training, we created engineered features like:\n",
    "- `age_group` (categorizing age into buckets)\n",
    "- `risk_factor_count` (counting total risk factors)\n",
    "- `is_senior` (flagging elderly patients)\n",
    "\n",
    "New patient data won't have these features, so we need to recreate them!\n",
    "\n",
    "### üîß This class:\n",
    "1. Takes raw patient data (age, BMI, etc.)\n",
    "2. Creates all the engineered features we used in training\n",
    "3. Ensures consistency between training and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecddf699-36a4-40c5-8d85-26137a0f8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeFeatureEngineering:\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        df['age_group'] = pd.cut(df['age'], \n",
    "                                 bins=[0, 40, 65, 120],  \n",
    "                                 labels=['young', 'middle', 'senior']) \n",
    "          \n",
    "        df['bmi_category'] = pd.cut(df['bmi'].fillna(28.0), \n",
    "                                    bins=[0, 18.5, 25, 30, 100],\n",
    "                                    labels=['underweight', 'normal', 'overweight', 'obese']) \n",
    "        \n",
    "\n",
    "        df['glucose_category'] = pd.cut(df['avg_glucose_level'],\n",
    "                                        bins=[0, 100, 126, 300],  \n",
    "                                        labels=['normal', 'prediabetic', 'very_high']) \n",
    "        \n",
    "        df['risk_factor_count'] = (\n",
    "            (df['hypertension'] == 1).astype(int) +\n",
    "            (df['heart_disease'] == 1).astype(int) +\n",
    "            (df['smoking_status'].isin(['smokes', 'formerly smoked'])).astype(int) +\n",
    "            (df['age'] > 65).astype(int) +\n",
    "            (df['avg_glucose_level'] > 126).astype(int)\n",
    "        )\n",
    "        df['bmi_glucose_ratio'] = df['bmi'].fillna(28.0) / df['avg_glucose_level']\n",
    "        df['bmi_missing'] = df['bmi'].isna().astype(int)\n",
    "        df['is_senior'] = (df['age'] >= 65).astype(int)\n",
    "        df['high_risk_group'] = ((df['age'] > 65) & \n",
    "                                ((df['hypertension'] == 1) | \n",
    "                                 (df['heart_disease'] == 1) | \n",
    "                                 (df['avg_glucose_level'] > 126))).astype(int)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414aa99-112a-4408-888d-738fae62557b",
   "metadata": {},
   "source": [
    "## **4Ô∏è‚É£ Create Prediction Function:**\n",
    "\n",
    "This function orchestrates the entire prediction process:\n",
    "1. Accepts raw patient data\n",
    "2. Applies feature engineering\n",
    "3. Runs preprocessing pipeline\n",
    "4. Gets model prediction\n",
    "5. Returns user-friendly results\n",
    "\n",
    "This function accepts raw input in dictionary or DataFrame form, applies preprocessing, and returns:\n",
    "- `prediction`: whether stroke is predicted (0/1)\n",
    "- `probability`: model confidence for stroke (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff56aad5-f03a-4dfb-b20e-0edd06a0ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stroke_risk(patient_input, model, pipeline):\n",
    "    \"\"\"\n",
    "    Updated prediction function that works with the new 7-feature pipeline\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([patient_input])\n",
    "    \n",
    "    feature_engineer = StrokeFeatureEngineering()\n",
    "    df_engineered = feature_engineer.transform(df)\n",
    "    \n",
    "    X_processed = pipeline.transform(df_engineered)\n",
    "    \n",
    "    probability = model.predict_proba(X_processed)[0][1]\n",
    "    prediction = model.predict(X_processed)[0]\n",
    "    \n",
    "    if probability < 0.1:\n",
    "        risk_level = \"Low\"\n",
    "        label = \"Low Stroke Risk\"\n",
    "    elif probability < 0.3:\n",
    "        risk_level = \"Moderate\"\n",
    "        label = \"Low Stroke Risk\"\n",
    "    elif probability < 0.5:\n",
    "        risk_level = \"High\"\n",
    "        label = \"Stroke Risk Detected\" \n",
    "    else:\n",
    "        risk_level = \"Very High\"\n",
    "        label = \"Stroke Risk Detected\"\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": int(prediction),\n",
    "        \"probability\": round(probability, 3),\n",
    "        \"risk_level\": risk_level,\n",
    "        \"label\": label \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d8c74-e085-4d2f-a2b4-3cc868659fab",
   "metadata": {},
   "source": [
    "## **5Ô∏è‚É£ Test with Example Patient üß™**\n",
    "\n",
    "The following code simulates a new patient record and passes it through the deployed model pipeline. \n",
    "\n",
    "The following code tests the final deployment-ready prediction function using two realistic scenarios. his serves as a sanity check to ensure all artifacts were loaded correctly and the prediction process works end-to-end:\n",
    "\n",
    "- **Case 1: High-risk elderly patient**  \n",
    "- **Case 2: Low-risk young patient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34f6d301-8f45-4653-909f-4b8ad0bb98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßì TEST CASE 1: High-risk elderly patient\n",
      "{\n",
      "  \"prediction\": 1,\n",
      "  \"probability\": 0.767,\n",
      "  \"risk_level\": \"Very High\",\n",
      "  \"label\": \"Stroke Risk Detected\"\n",
      "}\n",
      "\n",
      "üßë TEST CASE 2: Low-risk young patient\n",
      "{\n",
      "  \"prediction\": 0,\n",
      "  \"probability\": 0.112,\n",
      "  \"risk_level\": \"Moderate\",\n",
      "  \"label\": \"Low Stroke Risk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test case 1: High-risk elderly patient\n",
    "test_patient_1 = {\n",
    "    'gender': 'Female',\n",
    "    'age': 75,\n",
    "    'hypertension': 1,\n",
    "    'heart_disease': 1,\n",
    "    'ever_married': 'Yes',\n",
    "    'work_type': 'Private',\n",
    "    'Residence_type': 'Urban',\n",
    "    'avg_glucose_level': 228.69,\n",
    "    'bmi': 36.6,\n",
    "    'smoking_status': 'formerly smoked'\n",
    "}\n",
    "\n",
    "result_1 = predict_stroke_risk(test_patient_1, model, pipeline)\n",
    "print(\"üßì TEST CASE 1: High-risk elderly patient\")\n",
    "print(json.dumps(result_1, indent=2))\n",
    "\n",
    "# Test case 2: Low-risk young patient  \n",
    "test_patient_2 = {\n",
    "    'gender': 'Male',\n",
    "    'age': 32,\n",
    "    'hypertension': 0,\n",
    "    'heart_disease': 0,\n",
    "    'ever_married': 'No',\n",
    "    'work_type': 'Private',\n",
    "    'Residence_type': 'Urban',\n",
    "    'avg_glucose_level': 85.5,\n",
    "    'bmi': 23.1,\n",
    "    'smoking_status': 'never smoked'\n",
    "}\n",
    "\n",
    "result_2 = predict_stroke_risk(test_patient_2, model, pipeline)  # Use 'pipeline', not 'preprocessor'\n",
    "print(\"\\nüßë TEST CASE 2: Low-risk young patient\")\n",
    "print(json.dumps(result_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9f43e-0f7a-4ece-bdca-690bfb31c216",
   "metadata": {},
   "source": [
    "## **6Ô∏è‚É£ Deploy with Streamlit:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a4a38-74f4-40f3-ac8a-919d3aa8d14b",
   "metadata": {},
   "source": [
    "Streamlit converts Python scripts into interactive web apps. No web development knowledge needed!\n",
    "\n",
    "### üöÄ Deployment Steps:\n",
    "\n",
    "1. **Save the Streamlit app code** as `streamlit_app.py`\n",
    "2. **Install Streamlit**: `pip install streamlit`\n",
    "3. **Run the app**: `streamlit run streamlit_app.py`\n",
    "4. **Your browser will open** automatically at http://localhost:8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
